{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be80d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c204337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   review_id             100 non-null    object \n",
      " 1   user_id               100 non-null    object \n",
      " 2   business_id           100 non-null    object \n",
      " 3   stars                 100 non-null    int64  \n",
      " 4   useful                100 non-null    int64  \n",
      " 5   funny                 100 non-null    int64  \n",
      " 6   cool                  100 non-null    int64  \n",
      " 7   text                  100 non-null    object \n",
      " 8   date                  100 non-null    object \n",
      " 9   text_no_stop          100 non-null    object \n",
      " 10  text_stemmed          100 non-null    object \n",
      " 11  review_length         100 non-null    int64  \n",
      " 12  word_count            100 non-null    int64  \n",
      " 13  aspect                100 non-null    int64  \n",
      " 14  aspect_label          100 non-null    object \n",
      " 15  sentiment_polarity    100 non-null    float64\n",
      " 16  reviews_per_business  100 non-null    int64  \n",
      " 17  Food Quality          100 non-null    int64  \n",
      " 18   Customer Service     100 non-null    int64  \n",
      " 19  Place                 100 non-null    int64  \n",
      " 20  Menu & Price          100 non-null    int64  \n",
      " 21  Drinks                100 non-null    int64  \n",
      " 22  Time                  100 non-null    int64  \n",
      "dtypes: float64(1), int64(14), object(8)\n",
      "memory usage: 18.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>text_no_stop</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect</th>\n",
       "      <th>aspect_label</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>reviews_per_business</th>\n",
       "      <th>Food Quality</th>\n",
       "      <th>Customer Service</th>\n",
       "      <th>Place</th>\n",
       "      <th>Menu &amp; Price</th>\n",
       "      <th>Drinks</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hp3pIEuuk6t1RnKPTyt3hQ</td>\n",
       "      <td>-8oKMxks2GNqF9P41eE9LA</td>\n",
       "      <td>JnKdPqmgppB0CY7EuXaSCQ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>really enjoyed this place  gouda fondue app wa...</td>\n",
       "      <td>4/28/2013 6:11</td>\n",
       "      <td>really enjoyed place gouda fondue app deliciou...</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Specific Dishes and Restaurant</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mh1TcChvFaI6m4jvM5aR4Q</td>\n",
       "      <td>yrntNCr9bxPmKEU3ncjw8A</td>\n",
       "      <td>mi7JfdCRLfxzFG71oW0I1g</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>best coffeeespresso in town\\n\\nive been search...</td>\n",
       "      <td>1/26/2019 20:06</td>\n",
       "      <td>best coffeeespresso town ive searching good qu...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Menu and Pricing</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4XGBkfQXxpghKSbmGwtLoQ</td>\n",
       "      <td>BX2MDfo93cMOdsvAQ4-WDA</td>\n",
       "      <td>9ugpNKKhnYRa51qXoxUw_A</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>came here for dinner last night and the tacos ...</td>\n",
       "      <td>3/26/2016 1:45</td>\n",
       "      <td>came dinner last night tacos great lot meat sa...</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Overall Experience</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YhaWL-ioYp7dRjIMd8Z-gw</td>\n",
       "      <td>lcgjvFXX-dtvGvwXJ-UqDg</td>\n",
       "      <td>bKbvmpGy_L96qVtNeR_HNA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i just wanted to thank himalayan hut for the s...</td>\n",
       "      <td>5/5/2020 2:44</td>\n",
       "      <td>wanted thank himalayan hut service theyve prov...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Service and Wait Time</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1Jo-xTnxSybbs1v8rcTW_A</td>\n",
       "      <td>hoegTWA35mCxzi59DkZNng</td>\n",
       "      <td>iUZEGx29miZObLd6_lt7Vg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love the huevos rancheros here i make it a poi...</td>\n",
       "      <td>1/28/2018 0:18</td>\n",
       "      <td>love huevos rancheros make point eat breakfast...</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Overall Experience</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id   \n",
       "0  Hp3pIEuuk6t1RnKPTyt3hQ  -8oKMxks2GNqF9P41eE9LA  JnKdPqmgppB0CY7EuXaSCQ  \\\n",
       "1  mh1TcChvFaI6m4jvM5aR4Q  yrntNCr9bxPmKEU3ncjw8A  mi7JfdCRLfxzFG71oW0I1g   \n",
       "2  4XGBkfQXxpghKSbmGwtLoQ  BX2MDfo93cMOdsvAQ4-WDA  9ugpNKKhnYRa51qXoxUw_A   \n",
       "3  YhaWL-ioYp7dRjIMd8Z-gw  lcgjvFXX-dtvGvwXJ-UqDg  bKbvmpGy_L96qVtNeR_HNA   \n",
       "4  1Jo-xTnxSybbs1v8rcTW_A  hoegTWA35mCxzi59DkZNng  iUZEGx29miZObLd6_lt7Vg   \n",
       "\n",
       "   stars  useful  funny  cool   \n",
       "0      5       0      0     0  \\\n",
       "1      4       1      0     0   \n",
       "2      5       0      0     0   \n",
       "3      5       1      0     0   \n",
       "4      5       0      0     0   \n",
       "\n",
       "                                                text             date   \n",
       "0  really enjoyed this place  gouda fondue app wa...   4/28/2013 6:11  \\\n",
       "1  best coffeeespresso in town\\n\\nive been search...  1/26/2019 20:06   \n",
       "2  came here for dinner last night and the tacos ...   3/26/2016 1:45   \n",
       "3  i just wanted to thank himalayan hut for the s...    5/5/2020 2:44   \n",
       "4  love the huevos rancheros here i make it a poi...   1/28/2018 0:18   \n",
       "\n",
       "                                        text_no_stop  ... aspect   \n",
       "0  really enjoyed place gouda fondue app deliciou...  ...      4  \\\n",
       "1  best coffeeespresso town ive searching good qu...  ...      3   \n",
       "2  came dinner last night tacos great lot meat sa...  ...      2   \n",
       "3  wanted thank himalayan hut service theyve prov...  ...      1   \n",
       "4  love huevos rancheros make point eat breakfast...  ...      2   \n",
       "\n",
       "                     aspect_label  sentiment_polarity  reviews_per_business   \n",
       "0  Specific Dishes and Restaurant            0.683333                   137  \\\n",
       "1                Menu and Pricing            0.416667                    10   \n",
       "2              Overall Experience            0.600000                   237   \n",
       "3           Service and Wait Time            0.029167                    19   \n",
       "4              Overall Experience            0.400000                   349   \n",
       "\n",
       "  Food Quality   Customer Service  Place  Menu & Price  Drinks  Time  \n",
       "0            1                  1      0             0       0     0  \n",
       "1            0                  0      0             0       1     0  \n",
       "2            1                  0      0             0       0     0  \n",
       "3            1                  1      0             0       0     0  \n",
       "4            1                  0      0             0       0     0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time=pd.read_csv(\"ankur_100_sample_labels_time.csv\")\n",
    "print(df_time.info())\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2abe516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Quality</th>\n",
       "      <th>Customer Service</th>\n",
       "      <th>Place</th>\n",
       "      <th>Menu &amp; Price</th>\n",
       "      <th>Drinks</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count of 0</th>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count of 1</th>\n",
       "      <td>65</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count of -1</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Food Quality   Customer Service  Place  Menu & Price  Drinks   \n",
       "Count of 0             21                 43     70            61      83  \\\n",
       "Count of 1             65                 41     22            24      16   \n",
       "Count of -1            14                 16      8            15       1   \n",
       "\n",
       "             Time  \n",
       "Count of 0     81  \n",
       "Count of 1      9  \n",
       "Count of -1    10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_values(column):\n",
    "    counts = column.value_counts()\n",
    "    count_0 = counts.get(0, 0)\n",
    "    count_1 = counts.get(1, 0)\n",
    "    count_minus_1 = counts.get(-1, 0)\n",
    "    \n",
    "    return pd.Series({'Count of 0': count_0, 'Count of 1': count_1, 'Count of -1': count_minus_1})\n",
    "\n",
    "columns_to_count = ['Food Quality', ' Customer Service', 'Place', 'Menu & Price', 'Drinks', 'Time']\n",
    "\n",
    "counts_result = df_time[columns_to_count].apply(count_values)\n",
    "\n",
    "(counts_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc8b6c",
   "metadata": {},
   "source": [
    "# Testing the perfomance of different labels on manually labeled 100 rows extracted through stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abccde7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffa4679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for aspect: Food Quality\n",
      "Accuracy for Food Quality: 0.70\n",
      "Classification Report for Food Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.23      0.33      0.27        20\n",
      "weighted avg       0.49      0.70      0.58        20\n",
      "\n",
      "\n",
      "Training model for aspect:  Customer Service\n",
      "Accuracy for  Customer Service: 0.50\n",
      "Classification Report for  Customer Service:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.67      0.40      0.50        10\n",
      "           1       0.43      0.86      0.57         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.37      0.42      0.36        20\n",
      "weighted avg       0.48      0.50      0.45        20\n",
      "\n",
      "\n",
      "Training model for aspect: Place\n",
      "Accuracy for Place: 0.85\n",
      "Classification Report for Place:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.28      0.33      0.31        20\n",
      "weighted avg       0.72      0.85      0.78        20\n",
      "\n",
      "\n",
      "Training model for aspect: Menu & Price\n",
      "Accuracy for Menu & Price: 0.60\n",
      "Classification Report for Menu & Price:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         4\n",
      "           0       0.60      1.00      0.75        12\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.20      0.33      0.25        20\n",
      "weighted avg       0.36      0.60      0.45        20\n",
      "\n",
      "\n",
      "Training model for aspect: Drinks\n",
      "Accuracy for Drinks: 0.85\n",
      "Classification Report for Drinks:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.42      0.50      0.46        20\n",
      "weighted avg       0.72      0.85      0.78        20\n",
      "\n",
      "\n",
      "Training model for aspect: Time\n",
      "Accuracy for Time: 0.80\n",
      "Classification Report for Time:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.80      1.00      0.89        16\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.27      0.33      0.30        20\n",
      "weighted avg       0.64      0.80      0.71        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('ankur_100_sample_labels_time.csv')  \n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['text', 'Food Quality', ' Customer Service', 'Place', 'Menu & Price', 'Drinks', 'Time']\n",
    "data = data[columns]\n",
    "\n",
    "data[columns[1:]] = data[columns[1:]].fillna(0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a pipeline for text classification\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', MultinomialNB()) \n",
    "])\n",
    "\n",
    "# Train the model for each aspect\n",
    "for aspect in columns[1:]:\n",
    "    print(f\"\\nTraining model for aspect: {aspect}\")\n",
    "    # Fit the model\n",
    "    text_clf.fit(train_data['text'], train_data[aspect])\n",
    "\n",
    "    # Predictions on the test set\n",
    "    predictions = text_clf.predict(test_data['text'])\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(test_data[aspect], predictions)\n",
    "    report = classification_report(test_data[aspect], predictions)\n",
    "\n",
    "    print(f\"Accuracy for {aspect}: {accuracy:.2f}\")\n",
    "    print(f\"Classification Report for {aspect}:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db20efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for aspect: Food Quality\n",
      "Accuracy for Food Quality: 0.70\n",
      "Classification Report for Food Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.23      0.33      0.27        20\n",
      "weighted avg       0.49      0.70      0.58        20\n",
      "\n",
      "\n",
      "Training model for aspect:  Customer Service\n",
      "Accuracy for  Customer Service: 0.70\n",
      "Classification Report for  Customer Service:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.80      0.80      0.80        10\n",
      "           1       0.60      0.86      0.71         7\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.47      0.55      0.50        20\n",
      "weighted avg       0.61      0.70      0.65        20\n",
      "\n",
      "\n",
      "Training model for aspect: Place\n",
      "Accuracy for Place: 0.85\n",
      "Classification Report for Place:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.28      0.33      0.31        20\n",
      "weighted avg       0.72      0.85      0.78        20\n",
      "\n",
      "\n",
      "Training model for aspect: Menu & Price\n",
      "Accuracy for Menu & Price: 0.60\n",
      "Classification Report for Menu & Price:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         4\n",
      "           0       0.60      1.00      0.75        12\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.20      0.33      0.25        20\n",
      "weighted avg       0.36      0.60      0.45        20\n",
      "\n",
      "\n",
      "Training model for aspect: Drinks\n",
      "Accuracy for Drinks: 0.85\n",
      "Classification Report for Drinks:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.42      0.50      0.46        20\n",
      "weighted avg       0.72      0.85      0.78        20\n",
      "\n",
      "\n",
      "Training model for aspect: Time\n",
      "Accuracy for Time: 0.80\n",
      "Classification Report for Time:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.80      1.00      0.89        16\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.27      0.33      0.30        20\n",
      "weighted avg       0.64      0.80      0.71        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('ankur_100_sample_labels_time.csv')  # Replace 'your_dataset.csv' with the actual file path\n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['text', 'Food Quality', ' Customer Service', 'Place', 'Menu & Price', 'Drinks', 'Time']\n",
    "data = data[columns]\n",
    "\n",
    "# Fill NaN values in the target variables with 0\n",
    "data[columns[1:]] = data[columns[1:]].fillna(0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a pipeline for text classification using Random Forest\n",
    "\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', RandomForestClassifier())  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Train the model for each aspect\n",
    "for aspect in columns[1:]:\n",
    "    print(f\"\\nTraining model for aspect: {aspect}\")\n",
    "    # Fit the model\n",
    "    text_clf.fit(train_data['text'], train_data[aspect])\n",
    "\n",
    "    # Predictions on the test set\n",
    "    predictions = text_clf.predict(test_data['text'])\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(test_data[aspect], predictions)\n",
    "    report = classification_report(test_data[aspect], predictions)\n",
    "\n",
    "    print(f\"Accuracy for {aspect}: {accuracy:.2f}\")\n",
    "    print(f\"Classification Report for {aspect}:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2452915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for aspect: Food Quality\n",
      "Accuracy for Food Quality: 0.70\n",
      "Classification Report for Food Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.23      0.33      0.27        20\n",
      "weighted avg       0.49      0.70      0.58        20\n",
      "\n",
      "\n",
      "Training model for aspect:  Customer Service\n",
      "Accuracy for  Customer Service: 0.65\n",
      "Classification Report for  Customer Service:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.73      0.80      0.76        10\n",
      "           1       0.56      0.71      0.63         7\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.43      0.50      0.46        20\n",
      "weighted avg       0.56      0.65      0.60        20\n",
      "\n",
      "\n",
      "Training model for aspect: Place\n",
      "Accuracy for Place: 0.80\n",
      "Classification Report for Place:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.84      0.94      0.89        17\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.28      0.31      0.30        20\n",
      "weighted avg       0.72      0.80      0.76        20\n",
      "\n",
      "\n",
      "Training model for aspect: Menu & Price\n",
      "Accuracy for Menu & Price: 0.60\n",
      "Classification Report for Menu & Price:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         4\n",
      "           0       0.60      1.00      0.75        12\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.20      0.33      0.25        20\n",
      "weighted avg       0.36      0.60      0.45        20\n",
      "\n",
      "\n",
      "Training model for aspect: Drinks\n",
      "Accuracy for Drinks: 0.85\n",
      "Classification Report for Drinks:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.42      0.50      0.46        20\n",
      "weighted avg       0.72      0.85      0.78        20\n",
      "\n",
      "\n",
      "Training model for aspect: Time\n",
      "Accuracy for Time: 0.80\n",
      "Classification Report for Time:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.80      1.00      0.89        16\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.27      0.33      0.30        20\n",
      "weighted avg       0.64      0.80      0.71        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('ankur_100_sample_labels_time.csv')  \n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['text', 'Food Quality', ' Customer Service', 'Place', 'Menu & Price', 'Drinks', 'Time']\n",
    "data = data[columns]\n",
    "\n",
    "# Fill NaN values in the target variables with 0\n",
    "data[columns[1:]] = data[columns[1:]].fillna(0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a pipeline for text classification using Random Forest\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "# Train the model for each aspect\n",
    "for aspect in columns[1:]:\n",
    "    print(f\"\\nTraining model for aspect: {aspect}\")\n",
    "    # Fit the model\n",
    "    text_clf.fit(train_data['text'], train_data[aspect])\n",
    "\n",
    "    # Predictions on the test set\n",
    "    predictions = text_clf.predict(test_data['text'])\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(test_data[aspect], predictions)\n",
    "    report = classification_report(test_data[aspect], predictions)\n",
    "\n",
    "    print(f\"Accuracy for {aspect}: {accuracy:.2f}\")\n",
    "    print(f\"Classification Report for {aspect}:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601d379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "450d27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('ankur_100_sample_labels_time.csv')  \n",
    "# Select relevant columns\n",
    "columns = ['text', 'Food Quality', ' Customer Service', 'Place', 'Menu & Price', 'Drinks', 'Time']\n",
    "data = data[columns]\n",
    "\n",
    "# Fill NaN values in the target variables with 0\n",
    "data[columns[1:]] = data[columns[1:]].fillna(0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a dictionary to store results for each aspect\n",
    "results = []\n",
    "\n",
    "# Build a pipeline for text classification\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', MultinomialNB())  # You can replace this classifier with another (e.g., RandomForest, SVM, etc.)\n",
    "])\n",
    "\n",
    "# Train the model for each aspect\n",
    "for aspect in columns[1:]:\n",
    "    #print(f\"\\nTraining model for aspect: {aspect}\")\n",
    "    # Fit the model\n",
    "    text_clf.fit(train_data['text'], train_data[aspect])\n",
    "\n",
    "    # Predictions on the test set\n",
    "    predictions = text_clf.predict(test_data['text'])\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(test_data[aspect], predictions)\n",
    "    report = classification_report(test_data[aspect], predictions, output_dict=True)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    result = {\n",
    "        'Aspect': aspect,\n",
    "        'Model Used': 'Multinomial Naive Bayes',\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision (positive)': report['1']['precision'],\n",
    "        'Recall (positive)': report['1']['recall'],\n",
    "        'F1-score (positive)': report['1']['f1-score'],\n",
    "        'Precision (negative)': report['0']['precision'],\n",
    "        'Recall (negative)': report['0']['recall'],\n",
    "        'F1-score (negative)': report['0']['f1-score'],\n",
    "    }\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df_NB = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c406aa6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (positive)</th>\n",
       "      <th>Recall (positive)</th>\n",
       "      <th>F1-score (positive)</th>\n",
       "      <th>Precision (negative)</th>\n",
       "      <th>Recall (negative)</th>\n",
       "      <th>F1-score (negative)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Place</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Menu &amp; Price</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drinks</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Time</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Aspect               Model Used  Accuracy  Precision (positive)   \n",
       "0       Food Quality  Multinomial Naive Bayes      0.70              0.700000  \\\n",
       "1   Customer Service  Multinomial Naive Bayes      0.50              0.428571   \n",
       "2              Place  Multinomial Naive Bayes      0.85              0.000000   \n",
       "3       Menu & Price  Multinomial Naive Bayes      0.60              0.000000   \n",
       "4             Drinks  Multinomial Naive Bayes      0.85              0.000000   \n",
       "5               Time  Multinomial Naive Bayes      0.80              0.000000   \n",
       "\n",
       "   Recall (positive)  F1-score (positive)  Precision (negative)   \n",
       "0           1.000000             0.823529              0.000000  \\\n",
       "1           0.857143             0.571429              0.666667   \n",
       "2           0.000000             0.000000              0.850000   \n",
       "3           0.000000             0.000000              0.600000   \n",
       "4           0.000000             0.000000              0.850000   \n",
       "5           0.000000             0.000000              0.800000   \n",
       "\n",
       "   Recall (negative)  F1-score (negative)  \n",
       "0                0.0             0.000000  \n",
       "1                0.4             0.500000  \n",
       "2                1.0             0.918919  \n",
       "3                1.0             0.750000  \n",
       "4                1.0             0.918919  \n",
       "5                1.0             0.888889  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_NB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dde0b3",
   "metadata": {},
   "source": [
    "The provided result table shows the performance metrics of sentiment analysis models for different aspects of Yelp reviews. Here's an interpretation of the results:\n",
    "\n",
    "Food Quality Aspect:\n",
    "\n",
    "Model Used: Multinomial Naive Bayes\n",
    "Accuracy: 0.70\n",
    "Precision (positive): 0.70\n",
    "Recall (positive): 1.00\n",
    "F1-score (positive): 0.82\n",
    "Precision (negative): 0.00\n",
    "Recall (negative): 0.00\n",
    "F1-score (negative): 0.00\n",
    "Interpretation: The model achieved an accuracy of 70% for the Food Quality aspect. It has good precision, recall, and F1-score for the positive class, indicating that it performs well in identifying positive sentiments. However, it has low performance for the negative class, as indicated by the precision, recall, and F1-score of 0.00.\n",
    "\n",
    "Customer Service Aspect:\n",
    "\n",
    "Model Used: Multinomial Naive Bayes\n",
    "Accuracy: 0.50\n",
    "Precision (positive): 0.43\n",
    "Recall (positive): 0.86\n",
    "F1-score (positive): 0.57\n",
    "Precision (negative): 0.67\n",
    "Recall (negative): 0.40\n",
    "F1-score (negative): 0.50\n",
    "Interpretation: The model achieved an accuracy of 50% for the Customer Service aspect. It has moderate precision, recall, and F1-score for both positive and negative classes. The F1-score for the positive class is 0.57, indicating that the model is better at identifying positive sentiments.\n",
    "\n",
    "Place Aspect:\n",
    "\n",
    "Model Used: Multinomial Naive Bayes\n",
    "Accuracy: 0.85\n",
    "Precision (positive): 0.00\n",
    "Recall (positive): 0.00\n",
    "F1-score (positive): 0.00\n",
    "Precision (negative): 0.85\n",
    "Recall (negative): 1.00\n",
    "F1-score (negative): 0.92\n",
    "Interpretation: The model achieved an accuracy of 85% for the Place aspect. However, it has low performance for the positive class, as indicated by precision, recall, and F1-score of 0.00. It performs very well for the negative class, with a high F1-score of 0.92.\n",
    "\n",
    "Menu & Price Aspect:\n",
    "\n",
    "Model Used: Multinomial Naive Bayes\n",
    "Accuracy: 0.60\n",
    "Precision (positive): 0.00\n",
    "Recall (positive): 0.00\n",
    "F1-score (positive): 0.00\n",
    "Precision (negative): 0.60\n",
    "Recall (negative): 1.00\n",
    "F1-score (negative): 0.75\n",
    "Interpretation: The model achieved an accuracy of 60% for the Menu & Price aspect. Similar to the Place aspect, it has low performance for the positive class but performs well for the negative class with an F1-score of 0.75.\n",
    "\n",
    "Drinks Aspect:\n",
    "\n",
    "Model Used: Multinomial Naive Bayes\n",
    "Accuracy: 0.85\n",
    "Precision (positive): 0.00\n",
    "Recall (positive): 0.00\n",
    "F1-score (positive): 0.00\n",
    "Precision (negative): 0.85\n",
    "Recall (negative): 1.00\n",
    "F1-score (negative): 0.92\n",
    "Interpretation: The model achieved an accuracy of 85% for the Drinks aspect, similar to the Place aspect. It has low performance for the positive class but performs very well for the negative class with an F1-score of 0.92.\n",
    "\n",
    "Time Aspect:\n",
    "\n",
    "Model Used: Multinomial Naive Bayes\n",
    "Accuracy: 0.80\n",
    "Precision (positive): 0.00\n",
    "Recall (positive): 0.00\n",
    "F1-score (positive): 0.00\n",
    "Precision (negative): 0.80\n",
    "Recall (negative): 1.00\n",
    "F1-score (negative): 0.89\n",
    "Interpretation: The model achieved an accuracy of 80% for the Time aspect. Similar to the Menu & Price and Drinks aspects, it has low performance for the positive class but performs well for the negative class with an F1-score of 0.89.\n",
    "\n",
    "Overall, it appears that the Multinomial Naive Bayes model used for sentiment analysis has good performance for identifying positive sentiments but struggles to identify negative sentiments for most of the aspects. The models seem to have a bias toward predicting positive sentiments. Depending on your project's goals, you may need to consider different models or techniques to improve the performance, especially for negative sentiment detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "793e743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "# Define the list of aspects you want to analyze\n",
    "aspects = ['Food Quality', ' Customer Service', 'Place', 'Menu & Price', 'Drinks', 'Time']\n",
    "\n",
    "# Create a list to store results for each aspect\n",
    "results_list = []\n",
    "\n",
    "# Iterate through each aspect\n",
    "for aspect in aspects:\n",
    "    # Split the data into training and testing sets\n",
    "    X = df['text_no_stop']  # Text features\n",
    "    y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a TF-IDF vectorizer to convert text into numerical features\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    # Initialize and train the machine learning model (Logistic Regression in this case)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    result_dict = {\n",
    "        'Aspect': aspect,\n",
    "        'Model Used': 'Logistic Regression',  # Specify the model used here\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision (positive)': classification_rep['1']['precision'],\n",
    "        'Recall (positive)': classification_rep['1']['recall'],\n",
    "        'F1-score (positive)': classification_rep['1']['f1-score'],\n",
    "        'Precision (negative)': classification_rep['0']['precision'],\n",
    "        'Recall (negative)': classification_rep['0']['recall'],\n",
    "        'F1-score (negative)': classification_rep['0']['f1-score'],\n",
    "    }\n",
    "    \n",
    "    results_list.append(result_dict)\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df_logistic = pd.DataFrame(results_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5686b2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (positive)</th>\n",
       "      <th>Recall (positive)</th>\n",
       "      <th>F1-score (positive)</th>\n",
       "      <th>Precision (negative)</th>\n",
       "      <th>Recall (negative)</th>\n",
       "      <th>F1-score (negative)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Place</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Menu &amp; Price</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drinks</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Time</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Aspect           Model Used  Accuracy  Precision (positive)   \n",
       "0       Food Quality  Logistic Regression      0.70              0.700000  \\\n",
       "1   Customer Service  Logistic Regression      0.65              0.545455   \n",
       "2              Place  Logistic Regression      0.85              0.000000   \n",
       "3       Menu & Price  Logistic Regression      0.60              0.000000   \n",
       "4             Drinks  Logistic Regression      0.85              0.000000   \n",
       "5               Time  Logistic Regression      0.80              0.000000   \n",
       "\n",
       "   Recall (positive)  F1-score (positive)  Precision (negative)   \n",
       "0           1.000000             0.823529              0.000000  \\\n",
       "1           0.857143             0.666667              0.777778   \n",
       "2           0.000000             0.000000              0.850000   \n",
       "3           0.000000             0.000000              0.600000   \n",
       "4           0.000000             0.000000              0.850000   \n",
       "5           0.000000             0.000000              0.800000   \n",
       "\n",
       "   Recall (negative)  F1-score (negative)  \n",
       "0                0.0             0.000000  \n",
       "1                0.7             0.736842  \n",
       "2                1.0             0.918919  \n",
       "3                1.0             0.750000  \n",
       "4                1.0             0.918919  \n",
       "5                1.0             0.888889  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd03b7",
   "metadata": {},
   "source": [
    "Food Quality Aspect:\n",
    "\n",
    "Model Used: Logistic Regression\n",
    "Accuracy: 0.70\n",
    "Precision (positive): 0.70\n",
    "Recall (positive): 1.00\n",
    "F1-score (positive): 0.82\n",
    "Precision (negative): 0.00\n",
    "Recall (negative): 0.00\n",
    "F1-score (negative): 0.00\n",
    "Interpretation: The Logistic Regression model achieves similar performance as the Multinomial Naive Bayes model for the Food Quality aspect. It has good precision, recall, and F1-score for the positive class but low performance for the negative class.\n",
    "\n",
    "Customer Service Aspect:\n",
    "\n",
    "Model Used: Logistic Regression\n",
    "Accuracy: 0.65\n",
    "Precision (positive): 0.55\n",
    "Recall (positive): 0.86\n",
    "F1-score (positive): 0.67\n",
    "Precision (negative): 0.78\n",
    "Recall (negative): 0.70\n",
    "F1-score (negative): 0.74\n",
    "Interpretation: The Logistic Regression model performs slightly better than the Multinomial Naive Bayes model for the Customer Service aspect. It has moderate precision, recall, and F1-score for both positive and negative classes.\n",
    "\n",
    "Place Aspect:\n",
    "\n",
    "Model Used: Logistic Regression\n",
    "Accuracy: 0.85\n",
    "Precision (positive): 0.00\n",
    "Recall (positive): 0.00\n",
    "F1-score (positive): 0.00\n",
    "Precision (negative): 0.85\n",
    "Recall (negative): 1.00\n",
    "F1-score (negative): 0.92\n",
    "Interpretation: The Logistic Regression model achieves the same performance as the Multinomial Naive Bayes model for the Place aspect, with high accuracy and excellent performance for the negative class but poor performance for the positive class.\n",
    "\n",
    "Menu & Price Aspect:\n",
    "\n",
    "Model Used: Logistic Regression\n",
    "Accuracy: 0.60\n",
    "Precision (positive): 0.00\n",
    "Recall (positive): 0.00\n",
    "F1-score (positive): 0.00\n",
    "Precision (negative): 0.60\n",
    "Recall (negative): 1.00\n",
    "F1-score (negative): 0.75\n",
    "Interpretation: The Logistic Regression model performs similarly to the Multinomial Naive Bayes model for the Menu & Price aspect, with low performance for the positive class and better performance for the negative class.\n",
    "\n",
    "Drinks Aspect:\n",
    "\n",
    "Model Used: Logistic Regression\n",
    "Accuracy: 0.85\n",
    "Precision (positive): 0.00\n",
    "Recall (positive): 0.00\n",
    "F1-score (positive): 0.00\n",
    "Precision (negative): 0.85\n",
    "Recall (negative): 1.00\n",
    "F1-score (negative): 0.92\n",
    "Interpretation: The Logistic Regression model achieves the same high accuracy and performance as the Multinomial Naive Bayes model for the Drinks aspect, with poor performance for the positive class and excellent performance for the negative class.\n",
    "\n",
    "Time Aspect:\n",
    "\n",
    "Model Used: Logistic Regression\n",
    "Accuracy: 0.80\n",
    "Precision (positive): 0.00\n",
    "Recall (positive): 0.00\n",
    "F1-score (positive): 0.00\n",
    "Precision (negative): 0.80\n",
    "Recall (negative): 1.00\n",
    "F1-score (negative): 0.89\n",
    "Interpretation: The Logistic Regression model performs similarly to the Multinomial Naive Bayes model for the Time aspect, with low performance for the positive class and good performance for the negative class.\n",
    "\n",
    "Overall, the Logistic Regression model exhibits similar patterns of performance to the Multinomial Naive Bayes model. It performs well in identifying positive sentiments but struggles to identify negative sentiments for most aspects. Like the previous model, it also seems to have a bias toward predicting positive sentiments. Depending on your project's goals, you may consider different models or techniques to improve negative sentiment detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc746a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3b53378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for aspect: Food Quality\n",
      "Accuracy for Food Quality: 0.70\n",
      "Classification Report for Food Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.23      0.33      0.27        20\n",
      "weighted avg       0.49      0.70      0.58        20\n",
      "\n",
      "\n",
      "Training model for aspect:  Customer Service\n",
      "Accuracy for  Customer Service: 0.65\n",
      "Classification Report for  Customer Service:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.73      0.80      0.76        10\n",
      "           1       0.56      0.71      0.63         7\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.43      0.50      0.46        20\n",
      "weighted avg       0.56      0.65      0.60        20\n",
      "\n",
      "\n",
      "Training model for aspect: Place\n",
      "Accuracy for Place: 0.80\n",
      "Classification Report for Place:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.84      0.94      0.89        17\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.28      0.31      0.30        20\n",
      "weighted avg       0.72      0.80      0.76        20\n",
      "\n",
      "\n",
      "Training model for aspect: Menu & Price\n",
      "Accuracy for Menu & Price: 0.60\n",
      "Classification Report for Menu & Price:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         4\n",
      "           0       0.60      1.00      0.75        12\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.20      0.33      0.25        20\n",
      "weighted avg       0.36      0.60      0.45        20\n",
      "\n",
      "\n",
      "Training model for aspect: Drinks\n",
      "Accuracy for Drinks: 0.85\n",
      "Classification Report for Drinks:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.42      0.50      0.46        20\n",
      "weighted avg       0.72      0.85      0.78        20\n",
      "\n",
      "\n",
      "Training model for aspect: Time\n",
      "Accuracy for Time: 0.80\n",
      "Classification Report for Time:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.80      1.00      0.89        16\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.27      0.33      0.30        20\n",
      "weighted avg       0.64      0.80      0.71        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('ankur_100_sample_labels_time.csv')  # Replace 'your_dataset.csv' with the actual file path\n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['text', 'Food Quality', ' Customer Service', 'Place', 'Menu & Price', 'Drinks', 'Time']\n",
    "data = data[columns]\n",
    "\n",
    "# Fill NaN values in the target variables with 0\n",
    "data[columns[1:]] = data[columns[1:]].fillna(0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a pipeline for text classification using Random Forest\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "# Train the model for each aspect\n",
    "for aspect in columns[1:]:\n",
    "    print(f\"\\nTraining model for aspect: {aspect}\")\n",
    "    # Fit the model\n",
    "    text_clf.fit(train_data['text'], train_data[aspect])\n",
    "\n",
    "    # Predictions on the test set\n",
    "    predictions = text_clf.predict(test_data['text'])\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(test_data[aspect], predictions)\n",
    "    report = classification_report(test_data[aspect], predictions)\n",
    "\n",
    "    print(f\"Accuracy for {aspect}: {accuracy:.2f}\")\n",
    "    print(f\"Classification Report for {aspect}:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99db39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d860f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for aspect: Food Quality\n",
      "Accuracy for Food Quality: 0.70\n",
      "Classification Report for Food Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.23      0.33      0.27        20\n",
      "weighted avg       0.49      0.70      0.58        20\n",
      "\n",
      "\n",
      "Training model for aspect:  Customer Service\n",
      "Accuracy for  Customer Service: 0.50\n",
      "Classification Report for  Customer Service:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.67      0.40      0.50        10\n",
      "           1       0.43      0.86      0.57         7\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.37      0.42      0.36        20\n",
      "weighted avg       0.48      0.50      0.45        20\n",
      "\n",
      "\n",
      "Training model for aspect: Place\n",
      "Accuracy for Place: 0.85\n",
      "Classification Report for Place:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.28      0.33      0.31        20\n",
      "weighted avg       0.72      0.85      0.78        20\n",
      "\n",
      "\n",
      "Training model for aspect: Menu & Price\n",
      "Accuracy for Menu & Price: 0.60\n",
      "Classification Report for Menu & Price:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         4\n",
      "           0       0.60      1.00      0.75        12\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.20      0.33      0.25        20\n",
      "weighted avg       0.36      0.60      0.45        20\n",
      "\n",
      "\n",
      "Training model for aspect: Drinks\n",
      "Accuracy for Drinks: 0.85\n",
      "Classification Report for Drinks:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.42      0.50      0.46        20\n",
      "weighted avg       0.72      0.85      0.78        20\n",
      "\n",
      "\n",
      "Training model for aspect: Time\n",
      "Accuracy for Time: 0.80\n",
      "Classification Report for Time:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.80      1.00      0.89        16\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.27      0.33      0.30        20\n",
      "weighted avg       0.64      0.80      0.71        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('ankur_100_sample_labels_time.csv')  # Replace 'your_dataset.csv' with the actual file path\n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['text', 'Food Quality', ' Customer Service', 'Place', 'Menu & Price', 'Drinks', 'Time']\n",
    "data = data[columns]\n",
    "\n",
    "# Fill NaN values in the target variables with 0\n",
    "data[columns[1:]] = data[columns[1:]].fillna(0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a pipeline for text classification\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', MultinomialNB())  # You can replace this classifier with another (e.g., RandomForest, SVM, etc.)\n",
    "])\n",
    "\n",
    "# Train the model for each aspect\n",
    "for aspect in columns[1:]:\n",
    "    print(f\"\\nTraining model for aspect: {aspect}\")\n",
    "    # Fit the model\n",
    "    text_clf.fit(train_data['text'], train_data[aspect])\n",
    "\n",
    "    # Predictions on the test set\n",
    "    predictions = text_clf.predict(test_data['text'])\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(test_data[aspect], predictions)\n",
    "    report = classification_report(test_data[aspect], predictions)\n",
    "\n",
    "    print(f\"Accuracy for {aspect}: {accuracy:.2f}\")\n",
    "    print(f\"Classification Report for {aspect}:\\n{report}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c24a68",
   "metadata": {},
   "source": [
    "## checking Perfomance on individual aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c033791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Food Quality\n",
      "Accuracy: 0.70\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.23      0.33      0.27        20\n",
      "weighted avg       0.49      0.70      0.58        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "# Define the aspect you want to analyze\n",
    "aspect = 'Food Quality'  # Replace with the aspect you are working on\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['text_no_stop']  # Text features\n",
    "y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text into numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the machine learning model (Logistic Regression in this case)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Aspect: {aspect}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6640c98",
   "metadata": {},
   "source": [
    "The model performs well in identifying positive sentiments for \"Food Quality\" with a high recall (1.00) and a reasonable F1-score (0.82).\n",
    "\n",
    "However, the model does not perform well in identifying negative sentiments, as indicated by precision, recall, and F1-score, all of which are 0 for the negative class.\n",
    "The overall accuracy of 0.70 suggests that the model's performance is driven by its ability to identify positive sentiments, but it lacks the ability to identify negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "020a8414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Food Quality\n",
      "Accuracy: 0.65\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.72      0.93      0.81        14\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.24      0.31      0.27        20\n",
      "weighted avg       0.51      0.65      0.57        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "# Define the aspect you want to analyze\n",
    "aspect = 'Food Quality'  # Replace with the aspect you are working on\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['text_no_stop']  # Text features\n",
    "y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text into numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Aspect: {aspect}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61422943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24b3c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Food Quality\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.58      0.40      0.39        20\n",
      "weighted avg       0.77      0.75      0.68        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "# Define the aspect you want to analyze\n",
    "aspect = 'Food Quality'  # Replace with the aspect you are working on\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['text_no_stop']  # Text features\n",
    "y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text into numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class (1 for positive sentiment)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Initialize and train the machine learning model (Logistic Regression in this case)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Aspect: {aspect}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97200f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect:  Customer Service\n",
      "Accuracy: 0.70\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.33      0.50         3\n",
      "           0       0.88      0.70      0.78        10\n",
      "           1       0.55      0.86      0.67         7\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.81      0.63      0.65        20\n",
      "weighted avg       0.78      0.70      0.70        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "# Define the aspect you want to analyze\n",
    "aspect = ' Customer Service'  # Replace with the aspect you are working on\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['text_no_stop']  # Text features\n",
    "y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text into numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class (1 for positive sentiment)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Initialize and train the machine learning model (Logistic Regression in this case)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Aspect: {aspect}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8aaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0817fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Place\n",
      "Accuracy: 0.65\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       0.81      0.76      0.79        17\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.27      0.25      0.26        20\n",
      "weighted avg       0.69      0.65      0.67        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "# Define the aspect you want to analyze\n",
    "aspect = 'Place'  # Replace with the aspect you are working on\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['text_no_stop']  # Text features\n",
    "y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text into numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class (1 for positive sentiment)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Initialize and train the machine learning model (Logistic Regression in this case)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Aspect: {aspect}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5e201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55a1d747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Menu & Price\n",
      "Accuracy: 0.70\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.25      0.40         4\n",
      "           0       0.69      0.92      0.79        12\n",
      "           1       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.78      0.56      0.59        20\n",
      "weighted avg       0.75      0.70      0.67        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "# Define the aspect you want to analyze\n",
    "aspect = 'Menu & Price'  # Replace with the aspect you are working on\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['text_no_stop']  # Text features\n",
    "y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text into numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class (1 for positive sentiment)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Initialize and train the machine learning model (Logistic Regression in this case)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Aspect: {aspect}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bbb512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Time\n",
      "Accuracy: 0.80\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         3\n",
      "           0       0.80      1.00      0.89        16\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.27      0.33      0.30        20\n",
      "weighted avg       0.64      0.80      0.71        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "aspect = 'Time'  \n",
    "# Split the data into training and testing sets\n",
    "X = df['text_no_stop']  # Text features\n",
    "y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text into numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class (1 for positive sentiment)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Initialize and train the machine learning model (Logistic Regression in this case)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Aspect: {aspect}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6909d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dd3ebd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Food Quality\n",
      "Accuracy: 0.70\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         1\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.72      0.93      0.81        14\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.57      0.38      0.38        20\n",
      "weighted avg       0.76      0.70      0.65        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv('ankur_100_sample_labels_time.csv')\n",
    "\n",
    "# Define the aspect you want to analyze\n",
    "aspect = 'Food Quality'  # Replace with the aspect you are working on\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['text_no_stop']  # Text features\n",
    "y = df[aspect]  # Aspect sentiment labels (0 for negative, 1 for positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TF-IDF vectorizer to convert text into numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class (1 for positive sentiment)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Aspect: {aspect}')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb363b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
