{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa773da",
   "metadata": {},
   "source": [
    "### Supervised Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb799b",
   "metadata": {},
   "source": [
    "# select tfidf settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba9d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 of 5\n",
      "Run 2 of 5\n",
      "Run 3 of 5\n",
      "Run 4 of 5\n",
      "Run 5 of 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF Settings String</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_df': 0.2, 'norm': 'l2', 'sublinear_tf': True}</td>\n",
       "      <td>0.785641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}</td>\n",
       "      <td>0.802064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_df': 0.75, 'min_df': 3, 'norm': 'l1', 'sublinear_tf': False}</td>\n",
       "      <td>0.781374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_df': 0.9, 'min_df': 1, 'norm': 'l2', 'sublinear_tf': True}</td>\n",
       "      <td>0.789161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TF-IDF Settings String  \\\n",
       "0                 {'max_df': 0.2, 'norm': 'l2', 'sublinear_tf': True}   \n",
       "1   {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}   \n",
       "2  {'max_df': 0.75, 'min_df': 3, 'norm': 'l1', 'sublinear_tf': False}   \n",
       "3    {'max_df': 0.9, 'min_df': 1, 'norm': 'l2', 'sublinear_tf': True}   \n",
       "\n",
       "    AUC-ROC  \n",
       "0  0.785641  \n",
       "1  0.802064  \n",
       "2  0.781374  \n",
       "3  0.789161  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "delimiter = ','\n",
    "\n",
    "# Read the data file\n",
    "try:\n",
    "    yelp_data = pd.read_csv('stratified_sample_4.csv', delimiter=delimiter)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error reading the data file: {e}\")\n",
    "\n",
    "X = yelp_data['text']\n",
    "aspects = ['Food Quality', 'Customer Service', 'Place', 'Menu_and_Pricing', 'Drinks', 'Time']\n",
    "yelp_data[aspects] = yelp_data[aspects].fillna(0)\n",
    "\n",
    "# Define different TF-IDF settings to try\n",
    "tfidf_settings_list = [\n",
    "    {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False},\n",
    "    {'max_df': 0.75, 'min_df': 3, 'norm': 'l1', 'sublinear_tf': False},\n",
    "    {'max_df': 0.9, 'min_df': 1, 'norm': 'l2', 'sublinear_tf': True},\n",
    "    {'max_df': 0.2, 'norm': 'l2', 'sublinear_tf': True}\n",
    "]\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Create an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# Number of runs\n",
    "num_runs = 5\n",
    "\n",
    "# Perform the process multiple times\n",
    "for run in range(num_runs):\n",
    "    print(f\"Run {run + 1} of {num_runs}\")\n",
    "\n",
    "    # Iterate over each aspect\n",
    "    for aspect in aspects:\n",
    "        y = yelp_data[aspect]\n",
    "\n",
    "        for tfidf_params in tfidf_settings_list:\n",
    "            # Create a TF-IDF vectorizer with the specified parameters\n",
    "            tfidf_vectorizer = TfidfVectorizer(**tfidf_params)\n",
    "\n",
    "            # Transform the text data\n",
    "            X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "            for clf_name, clf in classifiers.items():\n",
    "                # Oversample the minority class using RandomOverSampler\n",
    "                oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "                X_resampled, y_resampled = oversampler.fit_resample(X_tfidf, y)\n",
    "\n",
    "                # Split the resampled data into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Combine classes 1 and 0 as the positive class\n",
    "                y_train_combined = (y_train == 1) | (y_train == 0)\n",
    "                y_test_combined = (y_test == 1) | (y_test == 0)\n",
    "\n",
    "                X_train_combined = X_train[y_train_combined]\n",
    "                y_train_combined = y_train[y_train_combined]\n",
    "                X_test_combined = X_test[y_test_combined]\n",
    "                y_test_combined = y_test[y_test_combined]\n",
    "\n",
    "                # Train the classifier\n",
    "                clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "                # Calculate AUC-ROC for the aspect by combining classes 1 and 0 as the positive class\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_test_combined, clf.predict_proba(X_test_combined)[:, 1])  # Assuming positive class is 1\n",
    "                except ValueError:\n",
    "                    roc_auc = 0.0  # Set to 0 if there is only one class in y_test for the current aspect\n",
    "\n",
    "                # Store the results in the list\n",
    "                results_list.append({\n",
    "                    'Aspect': aspect,\n",
    "                    'TF-IDF Settings': tfidf_params,\n",
    "                    'Classifier': clf_name,\n",
    "                    'AUC-ROC': roc_auc\n",
    "                })\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "results_df['TF-IDF Settings String'] = results_df['TF-IDF Settings'].apply(str)\n",
    "mean_auc_roc_by_settings = results_df.groupby(['TF-IDF Settings String'])['AUC-ROC'].mean().reset_index()\n",
    "mean_auc_roc_by_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d97812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic (Setting 1 vs. Setting 2): 5.092012885346961, p-value: 9.818216434457722e-07\n",
      "T-statistic (Setting 1 vs. Setting 3): 3.7550997031833333, p-value: 0.00015435030388943587\n",
      "T-statistic (Setting 2 vs. Setting 3): -1.4871829923069535, p-value: 0.9297495769358587\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Define the AUC-ROC scores for each setting\n",
    "auc_roc_scores_1 = results_df[results_df['TF-IDF Settings'] == {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}]['AUC-ROC']\n",
    "auc_roc_scores_2 = results_df[results_df['TF-IDF Settings'] == {'max_df': 0.75, 'min_df': 3, 'norm': 'l1', 'sublinear_tf': False}]['AUC-ROC']\n",
    "auc_roc_scores_3 = results_df[results_df['TF-IDF Settings'] == {'max_df': 0.9, 'min_df': 1, 'norm': 'l2', 'sublinear_tf': True}]['AUC-ROC']\n",
    "\n",
    "# Perform paired t-test between auc_roc_scores_1 and auc_roc_scores_2\n",
    "t_stat_1_2, p_value_1_2 = stats.ttest_rel(auc_roc_scores_1, auc_roc_scores_2, alternative='greater')\n",
    "\n",
    "# Perform paired t-test between auc_roc_scores_1 and auc_roc_scores_3\n",
    "t_stat_1_3, p_value_1_3 = stats.ttest_rel(auc_roc_scores_1, auc_roc_scores_3, alternative='greater')\n",
    "\n",
    "# Perform paired t-test between auc_roc_scores_2 and auc_roc_scores_3\n",
    "t_stat_2_3, p_value_2_3 = stats.ttest_rel(auc_roc_scores_2, auc_roc_scores_3, alternative='greater')\n",
    "\n",
    "# Print the t-statistics and p-values\n",
    "print(f'T-statistic (Setting 1 vs. Setting 2): {t_stat_1_2}, p-value: {p_value_1_2}')\n",
    "print(f'T-statistic (Setting 1 vs. Setting 3): {t_stat_1_3}, p-value: {p_value_1_3}')\n",
    "print(f'T-statistic (Setting 2 vs. Setting 3): {t_stat_2_3}, p-value: {p_value_2_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28182c5",
   "metadata": {},
   "source": [
    "Based on t-test, we choose,\n",
    "\n",
    "{'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}\n",
    "\n",
    "as the tfidf setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b9660",
   "metadata": {},
   "source": [
    "# select best model for each aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b4ad998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 of 5\n",
      "Run 2 of 5\n",
      "Run 3 of 5\n",
      "Run 4 of 5\n",
      "Run 5 of 5\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "delimiter = ','\n",
    "\n",
    "# Read the data file\n",
    "try:\n",
    "    yelp_data = pd.read_csv('stratified_sample_4.csv', delimiter=delimiter)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error reading the data file: {e}\")\n",
    "\n",
    "X = yelp_data['text']\n",
    "aspects = ['Food Quality', 'Customer Service', 'Place', 'Menu_and_Pricing', 'Drinks', 'Time']\n",
    "yelp_data[aspects] = yelp_data[aspects].fillna(0)\n",
    "\n",
    "# Define different TF-IDF settings to try\n",
    "tfidf_settings_list = [\n",
    "    {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}\n",
    "]\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Bagging': BaggingClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Create an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# Number of runs\n",
    "num_runs = 5\n",
    "\n",
    "# Perform the process multiple times\n",
    "for run in range(num_runs):\n",
    "    print(f\"Run {run + 1} of {num_runs}\")\n",
    "\n",
    "    # Iterate over each aspect\n",
    "    for aspect in aspects:\n",
    "        y = yelp_data[aspect]\n",
    "\n",
    "        for tfidf_params in tfidf_settings_list:\n",
    "            # Create a TF-IDF vectorizer with the specified parameters\n",
    "            tfidf_vectorizer = TfidfVectorizer(**tfidf_params)\n",
    "\n",
    "            # Transform the text data\n",
    "            X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "            for clf_name, clf in classifiers.items():\n",
    "                # Oversample the minority class using RandomOverSampler\n",
    "                oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "                X_resampled, y_resampled = oversampler.fit_resample(X_tfidf, y)\n",
    "\n",
    "                # Split the resampled data into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Combine classes 1 and 0 as the positive class\n",
    "                y_train_combined = (y_train == 1) | (y_train == 0)\n",
    "                y_test_combined = (y_test == 1) | (y_test == 0)\n",
    "\n",
    "                X_train_combined = X_train[y_train_combined]\n",
    "                y_train_combined = y_train[y_train_combined]\n",
    "                X_test_combined = X_test[y_test_combined]\n",
    "                y_test_combined = y_test[y_test_combined]\n",
    "\n",
    "                # Train the classifier\n",
    "                clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "                # Calculate AUC-ROC for the aspect by combining classes 1 and 0 as the positive class\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_test_combined, clf.predict_proba(X_test_combined)[:, 1])  # Assuming positive class is 1\n",
    "                except ValueError:\n",
    "                    roc_auc = 0.0  # Set to 0 if there is only one class in y_test for the current aspect\n",
    "\n",
    "                # Store the results in the list\n",
    "                results_list.append({\n",
    "                    'Aspect': aspect,\n",
    "                    'TF-IDF Settings': tfidf_params,\n",
    "                    'Classifier': clf_name,\n",
    "                    'AUC-ROC': roc_auc\n",
    "                })\n",
    "\n",
    "# Create a DataFrame from the list of results\n",
    "results_df = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e13be940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aspect</th>\n",
       "      <th>TF-IDF Settings</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>{'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.925172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Drinks</td>\n",
       "      <td>{'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.886782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food Quality</td>\n",
       "      <td>{'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.885238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Menu_and_Pricing</td>\n",
       "      <td>{'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.847403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Place</td>\n",
       "      <td>{'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.796332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Time</td>\n",
       "      <td>{'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Aspect  \\\n",
       "10   Customer Service   \n",
       "178            Drinks   \n",
       "0        Food Quality   \n",
       "28   Menu_and_Pricing   \n",
       "18              Place   \n",
       "42               Time   \n",
       "\n",
       "                                                       TF-IDF Settings  \\\n",
       "10   {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}   \n",
       "178  {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}   \n",
       "0    {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}   \n",
       "28   {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}   \n",
       "18   {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}   \n",
       "42   {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}   \n",
       "\n",
       "              Classifier   AUC-ROC  \n",
       "10         Random Forest  0.925172  \n",
       "178        Random Forest  0.886782  \n",
       "0    Logistic Regression  0.885238  \n",
       "28     Gradient Boosting  0.847403  \n",
       "18         Random Forest  0.796332  \n",
       "42         Random Forest  1.000000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_auc_roc_per_aspect = results_df.groupby('Aspect')['AUC-ROC'].idxmax()\n",
    "best_auc_roc_rows = results_df.loc[best_auc_roc_per_aspect]\n",
    "best_auc_roc_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5e7694df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Customer Service\n",
      "TF-IDF Settings: {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}\n",
      "Classifier: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.98      0.97        61\n",
      "           0       0.63      0.91      0.75        44\n",
      "           1       0.91      0.55      0.68        53\n",
      "\n",
      "    accuracy                           0.82       158\n",
      "   macro avg       0.83      0.81      0.80       158\n",
      "weighted avg       0.85      0.82      0.81       158\n",
      "\n",
      "==================================================\n",
      "Aspect: Drinks\n",
      "TF-IDF Settings: {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}\n",
      "Classifier: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        88\n",
      "           0       0.89      1.00      0.94       116\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.93       219\n",
      "   macro avg       0.63      0.67      0.65       219\n",
      "weighted avg       0.87      0.93      0.90       219\n",
      "\n",
      "==================================================\n",
      "Aspect: Food Quality\n",
      "TF-IDF Settings: {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}\n",
      "Classifier: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.99      0.93        83\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.82      0.95      0.88        84\n",
      "\n",
      "    accuracy                           0.84       192\n",
      "   macro avg       0.56      0.65      0.60       192\n",
      "weighted avg       0.73      0.84      0.79       192\n",
      "\n",
      "==================================================\n",
      "Aspect: Menu_and_Pricing\n",
      "TF-IDF Settings: {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}\n",
      "Classifier: Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      1.00      0.96        87\n",
      "           0       0.86      0.98      0.91        91\n",
      "           1       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.93      0.69      0.68       200\n",
      "weighted avg       0.90      0.89      0.85       200\n",
      "\n",
      "==================================================\n",
      "Aspect: Place\n",
      "TF-IDF Settings: {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}\n",
      "Classifier: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        67\n",
      "           0       0.72      0.99      0.83        84\n",
      "           1       0.80      0.11      0.19        37\n",
      "\n",
      "    accuracy                           0.82       188\n",
      "   macro avg       0.84      0.70      0.67       188\n",
      "weighted avg       0.83      0.82      0.76       188\n",
      "\n",
      "==================================================\n",
      "Aspect: Time\n",
      "TF-IDF Settings: {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}\n",
      "Classifier: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       0.85      1.00      0.92       103\n",
      "           1       1.00      1.00      1.00        93\n",
      "\n",
      "    accuracy                           0.92       214\n",
      "   macro avg       0.62      0.67      0.64       214\n",
      "weighted avg       0.84      0.92      0.88       214\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define a function to display F1 score report\n",
    "def display_f1_score_report(X, y, tfidf_params, clf_name, clf):\n",
    "    # Create a TF-IDF vectorizer with the specified parameters\n",
    "    tfidf_vectorizer = TfidfVectorizer(**tfidf_params)\n",
    "\n",
    "    # Transform the text data\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "    # Oversample the minority class using RandomOverSampler\n",
    "    oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X_tfidf, y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Display the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"Aspect: {aspect}\")\n",
    "    print(f\"TF-IDF Settings: {tfidf_params}\")\n",
    "    print(f\"Classifier: {clf_name}\")\n",
    "    print(report)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Iterate over the specified best models and aspects\n",
    "best_models = [\n",
    "    {'Aspect': 'Customer Service', 'TF-IDF Settings': {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}, 'Classifier': 'Random Forest'},\n",
    "    {'Aspect': 'Drinks', 'TF-IDF Settings': {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}, 'Classifier': 'Random Forest'},\n",
    "    {'Aspect': 'Food Quality', 'TF-IDF Settings': {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}, 'Classifier': 'Logistic Regression'},\n",
    "    {'Aspect': 'Menu_and_Pricing', 'TF-IDF Settings': {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}, 'Classifier': 'Gradient Boosting'},\n",
    "    {'Aspect': 'Place', 'TF-IDF Settings': {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}, 'Classifier': 'Random Forest'},\n",
    "    {'Aspect': 'Time', 'TF-IDF Settings': {'max_df': 0.5, 'min_df': 2, 'norm': 'l2', 'sublinear_tf': False}, 'Classifier': 'Random Forest'}\n",
    "]\n",
    "\n",
    "for best_model in best_models:\n",
    "    aspect = best_model['Aspect']\n",
    "    tfidf_params = best_model['TF-IDF Settings']\n",
    "    clf_name = best_model['Classifier']\n",
    "    clf = classifiers[clf_name]  # Get the classifier object from the dictionary\n",
    "\n",
    "    # Call the display_f1_score_report function to display the report\n",
    "    display_f1_score_report(X, yelp_data[aspect], tfidf_params, clf_name, clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b7092",
   "metadata": {},
   "source": [
    "tfidf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aff43008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Food Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.99      0.94        83\n",
      "           0       1.00      0.12      0.21        25\n",
      "           1       0.82      0.95      0.88        84\n",
      "\n",
      "    accuracy                           0.86       192\n",
      "   macro avg       0.91      0.69      0.68       192\n",
      "weighted avg       0.88      0.86      0.82       192\n",
      "\n",
      "Accuracy for Food Quality: 0.859375\n",
      "\n",
      "Classification Report for Customer Service:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.98      0.94        61\n",
      "           0       0.76      0.89      0.82        44\n",
      "           1       0.90      0.68      0.77        53\n",
      "\n",
      "    accuracy                           0.85       158\n",
      "   macro avg       0.85      0.85      0.84       158\n",
      "weighted avg       0.86      0.85      0.85       158\n",
      "\n",
      "Accuracy for Customer Service: 0.8544303797468354\n",
      "\n",
      "Classification Report for Place:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99        67\n",
      "           0       0.77      0.94      0.85        84\n",
      "           1       0.72      0.35      0.47        37\n",
      "\n",
      "    accuracy                           0.85       188\n",
      "   macro avg       0.83      0.76      0.77       188\n",
      "weighted avg       0.84      0.85      0.83       188\n",
      "\n",
      "Accuracy for Place: 0.8457446808510638\n",
      "\n",
      "Classification Report for Menu_and_Pricing:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      1.00      0.98        87\n",
      "           0       0.83      0.99      0.90        91\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.59      0.66      0.63       200\n",
      "weighted avg       0.79      0.89      0.83       200\n",
      "\n",
      "Accuracy for Menu_and_Pricing: 0.885\n",
      "\n",
      "Classification Report for Drinks:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        88\n",
      "           0       0.89      1.00      0.94       116\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.93       219\n",
      "   macro avg       0.63      0.67      0.65       219\n",
      "weighted avg       0.87      0.93      0.90       219\n",
      "\n",
      "Accuracy for Drinks: 0.9315068493150684\n",
      "\n",
      "Classification Report for Time:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       0.85      0.97      0.91       103\n",
      "           1       0.96      1.00      0.98        93\n",
      "\n",
      "    accuracy                           0.90       214\n",
      "   macro avg       0.60      0.66      0.63       214\n",
      "weighted avg       0.83      0.90      0.86       214\n",
      "\n",
      "Accuracy for Time: 0.9018691588785047\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "delimiter = ','\n",
    "\n",
    "# Read the data file\n",
    "try:\n",
    "    yelp_data = pd.read_csv('stratified_sample_4.csv', delimiter=delimiter)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error reading the data file: {e}\")\n",
    "\n",
    "X = yelp_data['text']\n",
    "aspects = ['Food Quality', 'Customer Service', 'Place', 'Menu_and_Pricing', 'Drinks', 'Time']\n",
    "yelp_data[aspects] = yelp_data[aspects].fillna(0)\n",
    "\n",
    "# List of classifiers for ensemble learning\n",
    "classifiers = [\n",
    "    ('nb', MultinomialNB()),  # You can add more classifiers here\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42)),\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# Iterate over each aspect and build a model\n",
    "for aspect in aspects:\n",
    "    y = yelp_data[aspect]\n",
    "\n",
    "    # Oversample the minority class using RandomOverSampler\n",
    "    oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X.values.reshape(-1, 1), y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled.flatten(), y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a pipeline with TF-IDF vectorizer and the ensemble of classifiers\n",
    "    text_clf = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', VotingClassifier(estimators=classifiers, voting='soft'))\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = text_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"\\nClassification Report for {aspect}:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(f\"Accuracy for {aspect}: {accuracy_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ea0b3",
   "metadata": {},
   "source": [
    "incidence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a57029d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Food Quality:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.99      0.95        83\n",
      "           0       1.00      0.12      0.21        25\n",
      "           1       0.84      1.00      0.91        84\n",
      "\n",
      "    accuracy                           0.88       192\n",
      "   macro avg       0.92      0.70      0.69       192\n",
      "weighted avg       0.90      0.88      0.84       192\n",
      "\n",
      "Accuracy for Food Quality: 0.8802083333333334\n",
      "\n",
      "Classification Report for Customer Service:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.97      0.96        61\n",
      "           0       0.72      0.95      0.82        44\n",
      "           1       0.92      0.66      0.77        53\n",
      "\n",
      "    accuracy                           0.86       158\n",
      "   macro avg       0.87      0.86      0.85       158\n",
      "weighted avg       0.88      0.86      0.86       158\n",
      "\n",
      "Accuracy for Customer Service: 0.8607594936708861\n",
      "\n",
      "Classification Report for Place:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        67\n",
      "           0       0.76      0.99      0.86        84\n",
      "           1       0.92      0.30      0.45        37\n",
      "\n",
      "    accuracy                           0.86       188\n",
      "   macro avg       0.89      0.76      0.77       188\n",
      "weighted avg       0.88      0.86      0.83       188\n",
      "\n",
      "Accuracy for Place: 0.8563829787234043\n",
      "\n",
      "Classification Report for Menu_and_Pricing:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99        87\n",
      "           0       0.82      0.99      0.90        91\n",
      "           1       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.94      0.69      0.69       200\n",
      "weighted avg       0.91      0.90      0.86       200\n",
      "\n",
      "Accuracy for Menu_and_Pricing: 0.895\n",
      "\n",
      "Classification Report for Drinks:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        88\n",
      "           0       0.89      1.00      0.94       116\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.93       219\n",
      "   macro avg       0.63      0.67      0.65       219\n",
      "weighted avg       0.87      0.93      0.90       219\n",
      "\n",
      "Accuracy for Drinks: 0.9315068493150684\n",
      "\n",
      "Classification Report for Time:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        18\n",
      "           0       0.85      0.98      0.91       103\n",
      "           1       0.98      1.00      0.99        93\n",
      "\n",
      "    accuracy                           0.91       214\n",
      "   macro avg       0.61      0.66      0.63       214\n",
      "weighted avg       0.83      0.91      0.87       214\n",
      "\n",
      "Accuracy for Time: 0.9065420560747663\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "delimiter = ','\n",
    "\n",
    "# Read the data file\n",
    "try:\n",
    "    yelp_data = pd.read_csv('stratified_sample_4.csv', delimiter=delimiter)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error reading the data file: {e}\")\n",
    "\n",
    "X = yelp_data['text']\n",
    "aspects = ['Food Quality', 'Customer Service', 'Place', 'Menu_and_Pricing', 'Drinks', 'Time']\n",
    "yelp_data[aspects] = yelp_data[aspects].fillna(0)\n",
    "\n",
    "# List of classifiers for ensemble learning\n",
    "classifiers = [\n",
    "    ('nb', MultinomialNB()),  # You can add more classifiers here\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42)),\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# Iterate over each aspect and build a model\n",
    "for aspect in aspects:\n",
    "    y = yelp_data[aspect]\n",
    "\n",
    "    # Oversample the minority class using RandomOverSampler\n",
    "    oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X.values.reshape(-1, 1), y)\n",
    "\n",
    "    # Split the resampled data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled.flatten(), y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a pipeline with CountVectorizer (incidence matrix) and the ensemble of classifiers\n",
    "    text_clf = Pipeline([\n",
    "        ('count_vectorizer', CountVectorizer(binary=True)),\n",
    "        ('clf', VotingClassifier(estimators=classifiers, voting='soft'))\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    text_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = text_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"\\nClassification Report for {aspect}:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(f\"Accuracy for {aspect}: {accuracy_score(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a7a5cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_data = pd.read_csv('final_df_3040_labels.csv', delimiter=delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cd92c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Classifier for Food Quality: 53.87%\n",
      "Accuracy of Random Classifier for Customer Service: 39.21%\n",
      "Accuracy of Random Classifier for Place: 53.05%\n",
      "Accuracy of Random Classifier for Menu_and_Pricing: 53.87%\n",
      "Accuracy of Random Classifier for Drinks: 63.10%\n",
      "Accuracy of Random Classifier for Time: 67.87%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming yelp_data is your DataFrame\n",
    "yelp_data = yelp_data.dropna(subset=aspects)  # Drop rows with NaN in any of the aspect columns\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "train_data, test_data = train_test_split(yelp_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dictionary to store random classifier accuracies for each aspect\n",
    "random_classifier_accuracies = {}\n",
    "\n",
    "for aspect in aspects:\n",
    "    # Calculate probabilities based on training data\n",
    "    sentiment_counts = train_data[aspect].value_counts(normalize=True)\n",
    "    \n",
    "    # Generating random predictions based on these probabilities for the test set\n",
    "    random_predictions = np.random.choice(sentiment_counts.index, \n",
    "                                          size=len(test_data), \n",
    "                                          p=sentiment_counts.values)\n",
    "    \n",
    "    # Filter out NaN values from test_data for accurate comparison\n",
    "    test_aspect_data = test_data[aspect].dropna()\n",
    "\n",
    "    # Calculating accuracy\n",
    "    accuracy_random = accuracy_score(test_aspect_data, random_predictions[:len(test_aspect_data)])\n",
    "    random_classifier_accuracies[aspect] = accuracy_random\n",
    "\n",
    "# Displaying the accuracies\n",
    "for aspect, accuracy in random_classifier_accuracies.items():\n",
    "    print(f\"Accuracy of Random Classifier for {aspect}: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
